{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2443ac2d",
   "metadata": {},
   "source": [
    "# 03. LangChain ëª¨ë¸ ì§ë ¬í™”(Serialization) ê°€ì´ë“œ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” LangChain ëª¨ë¸ê³¼ ì²´ì¸ì„ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. í™˜ê²½ ì„¤ì • ë° LangSmith ì—°ê²°\n",
    "2. ì§ë ¬í™” ê°€ëŠ¥ì„± í™•ì¸ (`is_lc_serializable`)\n",
    "3. JSON ì§ë ¬í™” (`dumps`, `dumpd`)\n",
    "4. Pickle ì§ë ¬í™”\n",
    "5. ëª¨ë¸ ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤ìŠµ\n",
    "6. ì²´ì¸ ì§ë ¬í™” ì‹¤ìŠµ\n",
    "\n",
    "## ê°œìš”\n",
    "\n",
    "ëª¨ë¸ ì§ë ¬í™”ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ìƒí™©ì—ì„œ ìœ ìš©í•©ë‹ˆë‹¤:\n",
    "- **ëª¨ë¸ ë°°í¬**: í›ˆë ¨ëœ ëª¨ë¸ì„ í”„ë¡œë•ì…˜ í™˜ê²½ì— ë°°í¬\n",
    "- **ìºì‹±**: ë³µì¡í•œ ì²´ì¸ êµ¬ì„±ì„ ì €ì¥í•˜ì—¬ ì¬ì‚¬ìš©\n",
    "- **ë²„ì „ ê´€ë¦¬**: ëª¨ë¸ì˜ ë‹¤ì–‘í•œ ë²„ì „ì„ ê´€ë¦¬\n",
    "- **ê³µìœ **: íŒ€ì› ê°„ ëª¨ë¸ ì„¤ì • ê³µìœ \n",
    "\n",
    "## ì§ë ¬í™” ë°©ë²• ë¹„êµ\n",
    "\n",
    "| ë°©ë²• | ì¥ì  | ë‹¨ì  | ìš©ë„ |\n",
    "|------|------|------|------|\n",
    "| JSON (`dumps`) | ê°€ë…ì„± ì¢‹ìŒ, í”Œë«í¼ ë…ë¦½ì  | ì¼ë¶€ ê°ì²´ ì§ë ¬í™” ë¶ˆê°€ | ì„¤ì • ê³µìœ , ë””ë²„ê¹… |\n",
    "| Pickle | ëª¨ë“  Python ê°ì²´ ì§€ì› | Python ì „ìš©, ë³´ì•ˆ ìœ„í—˜ | ì™„ì „í•œ ê°ì²´ ì €ì¥ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9ca3e3",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° LangSmith ì—°ê²°\n",
    "\n",
    "ë¨¼ì € í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„í¬íŠ¸í•˜ê³  í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9afb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.load import dumps, dumpd, loads\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# is_lc_serializable í•¨ìˆ˜ ì„í¬íŠ¸ (ìµœì‹  ë²„ì „ ëŒ€ì‘)\n",
    "try:\n",
    "    from langchain_core.load import dumpd as _test_dumpd\n",
    "    def is_lc_serializable(obj):\n",
    "        \"\"\"ê°ì²´ê°€ LangChain ì§ë ¬í™” ê°€ëŠ¥í•œì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "        try:\n",
    "            _test_dumpd(obj)\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "except ImportError:\n",
    "    # ëŒ€ì²´ êµ¬í˜„\n",
    "    def is_lc_serializable(obj):\n",
    "        \"\"\"ê¸°ë³¸ êµ¬í˜„: dumpdë¡œ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "        try:\n",
    "            from langchain_core.load import dumpd\n",
    "            dumpd(obj)\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ í™•ì¸\n",
    "print(\"ğŸ” í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ì¤‘...\")\n",
    "\n",
    "# Google API í‚¤ í™•ì¸\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not google_api_key:\n",
    "    raise ValueError(\"âŒ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "print(\"âœ… Google API Key: ì„¤ì •ë¨\")\n",
    "\n",
    "# LangSmith API í‚¤ í™•ì¸ (ì„ íƒì‚¬í•­)\n",
    "langsmith_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "if langsmith_api_key:\n",
    "    print(\"âœ… LangSmith API Key: ì„¤ì •ë¨\")\n",
    "    # LangSmith ì„¤ì •\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"  # LangSmith ì¶”ì  í™œì„±í™”\n",
    "    os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = \"model-serialization-demo\"  # í”„ë¡œì íŠ¸ ì´ë¦„ ì„¤ì •\n",
    "    \n",
    "    print(f\"ğŸ“Š LangSmith í”„ë¡œì íŠ¸: {os.environ['LANGCHAIN_PROJECT']}\")\n",
    "    print(f\"ğŸ”„ LangSmith ì¶”ì  í™œì„±í™”: {os.environ['LANGCHAIN_TRACING_V2']}\")\n",
    "    print(\"ğŸŒ LangSmith ëŒ€ì‹œë³´ë“œ: https://smith.langchain.com/\")\n",
    "else:\n",
    "    print(\"âš ï¸  LangSmith API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"   LangSmith ì¶”ì  ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"\\nâœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ae45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini ëª¨ë¸ ì´ˆê¸°í™”\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.7,\n",
    "    max_output_tokens=200\n",
    ")\n",
    "\n",
    "print(\"ğŸ¤– Gemini ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
    "print(f\"   ëª¨ë¸: {llm.model}\")\n",
    "print(f\"   ì˜¨ë„: {llm.temperature}\")\n",
    "print(f\"   ìµœëŒ€ í† í°: {llm.max_output_tokens}\")\n",
    "\n",
    "# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸\n",
    "test_response = llm.invoke(\"ì•ˆë…•í•˜ì„¸ìš”!\")\n",
    "print(f\"\\nğŸ§ª í…ŒìŠ¤íŠ¸ ì‘ë‹µ: {test_response.content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637059e0",
   "metadata": {},
   "source": [
    "## 2. ì§ë ¬í™” ê°€ëŠ¥ì„± í™•ì¸ (`is_lc_serializable`)\n",
    "\n",
    "LangChainì˜ `is_lc_serializable` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°ì²´ê°€ ì§ë ¬í™” ê°€ëŠ¥í•œì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ì§ë ¬í™”ë€?\n",
    "- **ì§ë ¬í™”(Serialization)**: ê°ì²´ë¥¼ ì €ì¥ì´ë‚˜ ì „ì†¡ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜\n",
    "- **ì—­ì§ë ¬í™”(Deserialization)**: ì €ì¥ëœ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ê°ì²´ë¡œ ë³µì›\n",
    "\n",
    "### LangChain ì§ë ¬í™” ì§€ì›\n",
    "- LangChain ì»´í¬ë„ŒíŠ¸ë“¤ì€ ëŒ€ë¶€ë¶„ ì§ë ¬í™”ë¥¼ ì§€ì›\n",
    "- `@serializable` ë°ì½”ë ˆì´í„°ë¡œ ì§ë ¬í™” ê°€ëŠ¥ í´ë˜ìŠ¤ í‘œì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# ë‹¤ì–‘í•œ ê°ì²´ì˜ ì§ë ¬í™” ê°€ëŠ¥ì„± í™•ì¸\n",
    "############################################################################\n",
    "\n",
    "print(\"ğŸ” ì§ë ¬í™” ê°€ëŠ¥ì„± í™•ì¸\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. LLM ëª¨ë¸ í™•ì¸\n",
    "print(f\"1. ChatGoogleGenerativeAI: {is_lc_serializable(llm)}\")\n",
    "\n",
    "# 2. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í™•ì¸\n",
    "prompt = ChatPromptTemplate.from_template(\"ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”: {question}\")\n",
    "print(f\"2. ChatPromptTemplate: {is_lc_serializable(prompt)}\")\n",
    "\n",
    "# 3. ì¶œë ¥ íŒŒì„œ í™•ì¸\n",
    "parser = StrOutputParser()\n",
    "print(f\"3. StrOutputParser: {is_lc_serializable(parser)}\")\n",
    "\n",
    "# 4. ì²´ì¸ í™•ì¸ (LangChain Expression Language - LCEL)\n",
    "chain = prompt | llm | parser\n",
    "print(f\"4. Chain (prompt | llm | parser): {is_lc_serializable(chain)}\")\n",
    "\n",
    "# 5. ê°œë³„ ë©”ì‹œì§€ í™•ì¸\n",
    "human_msg = HumanMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”\")\n",
    "system_msg = SystemMessage(content=\"ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AIì…ë‹ˆë‹¤\")\n",
    "print(f\"5. HumanMessage: {is_lc_serializable(human_msg)}\")\n",
    "print(f\"6. SystemMessage: {is_lc_serializable(system_msg)}\")\n",
    "\n",
    "# 6. ì¼ë°˜ Python ê°ì²´ í™•ì¸\n",
    "regular_dict = {\"key\": \"value\"}\n",
    "print(f\"7. Regular Dict: {is_lc_serializable(regular_dict)}\")\n",
    "\n",
    "print(\"\\nâœ… ì§ë ¬í™” ê°€ëŠ¥ì„± í™•ì¸ ì™„ë£Œ!\")\n",
    "print(\"ğŸ“ True: LangChain ì§ë ¬í™” ì§€ì›, False: ì§€ì›í•˜ì§€ ì•ŠìŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0818530c",
   "metadata": {},
   "source": [
    "## 3. JSON ì§ë ¬í™” (`dumps`, `dumpd`)\n",
    "\n",
    "LangChainì—ì„œ ì œê³µí•˜ëŠ” JSON ì§ë ¬í™” í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•´ë´…ì‹œë‹¤.\n",
    "\n",
    "### í•¨ìˆ˜ë³„ íŠ¹ì§•\n",
    "- **`dumps()`**: ê°ì²´ë¥¼ JSON ë¬¸ìì—´ë¡œ ì§ë ¬í™”\n",
    "- **`dumpd()`**: ê°ì²´ë¥¼ Python ë”•ì…”ë„ˆë¦¬ë¡œ ì§ë ¬í™”\n",
    "- **`loads()`**: ì§ë ¬í™”ëœ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ê°ì²´ë¡œ ì—­ì§ë ¬í™”\n",
    "\n",
    "### ì¥ì \n",
    "- **ê°€ë…ì„±**: JSON í˜•íƒœë¡œ ì‚¬ëŒì´ ì½ê¸° ì‰¬ì›€\n",
    "- **í˜¸í™˜ì„±**: ë‹¤ì–‘í•œ ì–¸ì–´ì™€ í”Œë«í¼ì—ì„œ ì§€ì›\n",
    "- **ë””ë²„ê¹…**: êµ¬ì¡°ë¥¼ ì‰½ê²Œ íŒŒì•… ê°€ëŠ¥\n",
    "\n",
    "### ë‹¨ì \n",
    "- **ì œí•œì„±**: LangChain ì§€ì› ê°ì²´ë§Œ ì§ë ¬í™” ê°€ëŠ¥\n",
    "- **í¬ê¸°**: ë°”ì´ë„ˆë¦¬ í˜•ì‹ë³´ë‹¤ ìš©ëŸ‰ì´ í¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab213c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# JSON ì§ë ¬í™” ì‹¤ìŠµ\n",
    "############################################################################\n",
    "\n",
    "print(\"ğŸ“¦ JSON ì§ë ¬í™” ì‹¤ìŠµ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì§ë ¬í™”\n",
    "print(\"1. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì§ë ¬í™”\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# dumps() - JSON ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "prompt_json_str = dumps(prompt)\n",
    "print(f\"âœ… dumps() ì„±ê³µ! ê¸¸ì´: {len(prompt_json_str)} ë¬¸ì\")\n",
    "print(f\"ğŸ“„ JSON ë¯¸ë¦¬ë³´ê¸°: {prompt_json_str[:100]}...\")\n",
    "\n",
    "# dumpd() - Python ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜\n",
    "prompt_dict = dumpd(prompt)\n",
    "print(f\"\\nâœ… dumpd() ì„±ê³µ! í‚¤ ê°œìˆ˜: {len(prompt_dict)} ê°œ\")\n",
    "print(f\"ğŸ”‘ ë”•ì…”ë„ˆë¦¬ í‚¤ë“¤: {list(prompt_dict.keys())}\")\n",
    "\n",
    "# 2. ì²´ì¸ ì§ë ¬í™”\n",
    "print(\"\\n\\n2. ì²´ì¸ ì§ë ¬í™”\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "try:\n",
    "    chain_json_str = dumps(chain)\n",
    "    print(f\"âœ… ì²´ì¸ dumps() ì„±ê³µ! ê¸¸ì´: {len(chain_json_str)} ë¬¸ì\")\n",
    "    \n",
    "    chain_dict = dumpd(chain)\n",
    "    print(f\"âœ… ì²´ì¸ dumpd() ì„±ê³µ! í‚¤ ê°œìˆ˜: {len(chain_dict)} ê°œ\")\n",
    "    print(f\"ğŸ”‘ ì²´ì¸ ë”•ì…”ë„ˆë¦¬ í‚¤ë“¤: {list(chain_dict.keys())}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì²´ì¸ ì§ë ¬í™” ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# 3. ê°œë³„ ì»´í¬ë„ŒíŠ¸ í™•ì¸\n",
    "print(\"\\n\\n3. ê°œë³„ ì»´í¬ë„ŒíŠ¸ ì§ë ¬í™”\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "components = {\n",
    "    \"í”„ë¡¬í”„íŠ¸\": prompt,\n",
    "    \"íŒŒì„œ\": parser\n",
    "}\n",
    "\n",
    "for name, component in components.items():\n",
    "    try:\n",
    "        json_str = dumps(component)\n",
    "        print(f\"âœ… {name}: ì„±ê³µ ({len(json_str)} ë¬¸ì)\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {name}: ì‹¤íŒ¨ - {e}\")\n",
    "\n",
    "print(\"\\nâœ… JSON ì§ë ¬í™” ì‹¤ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2a4c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# JSON ì—­ì§ë ¬í™” ì‹¤ìŠµ\n",
    "############################################################################\n",
    "\n",
    "print(\"ğŸ”„ JSON ì—­ì§ë ¬í™” ì‹¤ìŠµ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë³µì›\n",
    "print(\"1. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë³µì›\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# JSON ë¬¸ìì—´ì—ì„œ ë³µì›\n",
    "restored_prompt = loads(prompt_json_str)\n",
    "print(f\"âœ… í”„ë¡¬í”„íŠ¸ ë³µì› ì„±ê³µ!\")\n",
    "print(f\"ğŸ“ ì›ë³¸ íƒ€ì…: {type(prompt)}\")\n",
    "print(f\"ğŸ“ ë³µì› íƒ€ì…: {type(restored_prompt)}\")\n",
    "print(f\"ğŸ” ë™ì¼ì„± í™•ì¸: {type(prompt) == type(restored_prompt)}\")\n",
    "\n",
    "# 2. ë³µì›ëœ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸\n",
    "print(\"\\n2. ë³µì›ëœ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "test_question = \"LangChainì´ë€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "\n",
    "# ì›ë³¸ í”„ë¡¬í”„íŠ¸\n",
    "original_messages = prompt.format_messages(question=test_question)\n",
    "print(f\"ğŸ“¤ ì›ë³¸ í”„ë¡¬í”„íŠ¸: {original_messages[0].content}\")\n",
    "\n",
    "# ë³µì›ëœ í”„ë¡¬í”„íŠ¸\n",
    "restored_messages = restored_prompt.format_messages(question=test_question)\n",
    "print(f\"ğŸ“¥ ë³µì› í”„ë¡¬í”„íŠ¸: {restored_messages[0].content}\")\n",
    "\n",
    "# ë™ì¼ì„± í™•ì¸\n",
    "print(f\"ğŸ” ë©”ì‹œì§€ ë™ì¼ì„±: {original_messages[0].content == restored_messages[0].content}\")\n",
    "\n",
    "# 3. ì‹¤ì œ LLM í˜¸ì¶œ í…ŒìŠ¤íŠ¸\n",
    "print(\"\\n3. ë³µì›ëœ í”„ë¡¬í”„íŠ¸ë¡œ LLM í˜¸ì¶œ\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "response = llm.invoke(restored_messages)\n",
    "print(f\"ğŸ’¬ ì‘ë‹µ: {response.content[:100]}...\")\n",
    "\n",
    "print(\"\\nâœ… JSON ì—­ì§ë ¬í™” ì‹¤ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb4121",
   "metadata": {},
   "source": [
    "## 4. Pickle ì§ë ¬í™”\n",
    "\n",
    "Pickleì€ Pythonì˜ í‘œì¤€ ì§ë ¬í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ê±°ì˜ ëª¨ë“  Python ê°ì²´ë¥¼ ì§ë ¬í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### Pickleì˜ íŠ¹ì§•\n",
    "\n",
    "**ì¥ì :**\n",
    "- **ì™„ì „ì„±**: ê±°ì˜ ëª¨ë“  Python ê°ì²´ ì§€ì›\n",
    "- **íš¨ìœ¨ì„±**: ë°”ì´ë„ˆë¦¬ í˜•ì‹ìœ¼ë¡œ í¬ê¸°ê°€ ì‘ìŒ\n",
    "- **ì†ë„**: JSONë³´ë‹¤ ë¹ ë¥¸ ì§ë ¬í™”/ì—­ì§ë ¬í™”\n",
    "\n",
    "**ë‹¨ì :**\n",
    "- **ë³´ì•ˆ ìœ„í—˜**: ì•…ì˜ì ì¸ ì½”ë“œ ì‹¤í–‰ ê°€ëŠ¥\n",
    "- **Python ì „ìš©**: ë‹¤ë¥¸ ì–¸ì–´ì—ì„œ ì½ì„ ìˆ˜ ì—†ìŒ\n",
    "- **ë²„ì „ ì˜ì¡´ì„±**: Python ë²„ì „ë³„ í˜¸í™˜ì„± ë¬¸ì œ ê°€ëŠ¥\n",
    "\n",
    "### ì‚¬ìš© ì‚¬ë¡€\n",
    "- **ê°œë°œ í™˜ê²½**: ë³µì¡í•œ ê°ì²´ì˜ ì„ì‹œ ì €ì¥\n",
    "- **ìºì‹±**: ì—°ì‚° ê²°ê³¼ì˜ ë¹ ë¥¸ ì €ì¥/ë¡œë“œ\n",
    "- **ëª¨ë¸ ë°±ì—…**: ì „ì²´ ëª¨ë¸ ìƒíƒœ ë³´ì¡´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb0035",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Pickle ì§ë ¬í™” ì‹¤ìŠµ\n",
    "############################################################################\n",
    "\n",
    "print(\"ğŸ¥’ Pickle ì§ë ¬í™” ì‹¤ìŠµ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. ë‹¨ì¼ ê°ì²´ Pickle ì €ì¥\n",
    "print(\"1. ë‹¨ì¼ ê°ì²´ Pickle ì €ì¥\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ pickleë¡œ ì €ì¥\n",
    "prompt_file = \"prompt_template.pkl\"\n",
    "with open(prompt_file, 'wb') as f:\n",
    "    pickle.dump(prompt, f)\n",
    "\n",
    "file_size = os.path.getsize(prompt_file)\n",
    "print(f\"âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì €ì¥ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“ íŒŒì¼ëª…: {prompt_file}\")\n",
    "print(f\"ğŸ“ íŒŒì¼ í¬ê¸°: {file_size} bytes\")\n",
    "\n",
    "# 2. ë³µí•© ê°ì²´ Pickle ì €ì¥\n",
    "print(\"\\n2. ë³µí•© ê°ì²´ Pickle ì €ì¥\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# ì—¬ëŸ¬ ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë¬¶ì–´ì„œ ì €ì¥ (LLM ì œì™¸)\n",
    "# LLM ê°ì²´ëŠ” gRPC ì—°ê²° ë•Œë¬¸ì— pickleë¡œ ì§ë ¬í™”í•  ìˆ˜ ì—†ìŒ\n",
    "model_components_safe = {\n",
    "    \"prompt\": prompt,\n",
    "    \"parser\": parser,\n",
    "    \"chain_config\": dumpd(chain),  # ì²´ì¸ì„ JSON í˜•íƒœë¡œ ì €ì¥\n",
    "    \"llm_config\": {\n",
    "        \"model\": llm.model,\n",
    "        \"temperature\": llm.temperature,\n",
    "        \"max_output_tokens\": llm.max_output_tokens\n",
    "    },\n",
    "    \"metadata\": {\n",
    "        \"created_at\": \"2025-09-05\",\n",
    "        \"model_name\": \"gemini-1.5-flash\",\n",
    "        \"version\": \"1.0\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ğŸ“ ì €ì¥ ê°€ëŠ¥í•œ ì»´í¬ë„ŒíŠ¸ í™•ì¸:\")\n",
    "for name, component in model_components_safe.items():\n",
    "    if name in [\"metadata\", \"llm_config\"]:\n",
    "        print(f\"   âœ… {name}: ì¼ë°˜ ë”•ì…”ë„ˆë¦¬ (ì €ì¥ ê°€ëŠ¥)\")\n",
    "    elif name == \"chain_config\":\n",
    "        print(f\"   âœ… {name}: JSON ì§ë ¬í™”ëœ ì²´ì¸ (ì €ì¥ ê°€ëŠ¥)\")\n",
    "    else:\n",
    "        try:\n",
    "            # í…ŒìŠ¤íŠ¸ë¡œ pickle ì§ë ¬í™” ì‹œë„\n",
    "            pickle.dumps(component)\n",
    "            print(f\"   âœ… {name}: Pickle ì§ë ¬í™” ê°€ëŠ¥\")\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ {name}: Pickle ì§ë ¬í™” ë¶ˆê°€ - {str(e)[:50]}...\")\n",
    "\n",
    "components_file = \"model_components.pkl\"\n",
    "with open(components_file, 'wb') as f:\n",
    "    pickle.dump(model_components_safe, f)\n",
    "\n",
    "components_size = os.path.getsize(components_file)\n",
    "print(f\"\\nâœ… ëª¨ë¸ ì»´í¬ë„ŒíŠ¸ ì €ì¥ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“ íŒŒì¼ëª…: {components_file}\")\n",
    "print(f\"ğŸ“ íŒŒì¼ í¬ê¸°: {components_size} bytes\")\n",
    "print(f\"ğŸ”§ ì €ì¥ëœ ì»´í¬ë„ŒíŠ¸: {list(model_components_safe.keys())}\")\n",
    "\n",
    "print(\"\\nâš ï¸  ì°¸ê³ : LLM ê°ì²´ëŠ” ì—°ê²° ì •ë³´ ë•Œë¬¸ì— pickleë¡œ ì €ì¥í•  ìˆ˜ ì—†ì–´\")\n",
    "print(\"   ì„¤ì • ì •ë³´ë§Œ ì €ì¥í•˜ê³  ë‚˜ì¤‘ì— ìƒˆë¡œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"\\nâœ… Pickle ì €ì¥ ì‹¤ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a71bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Pickle ì—­ì§ë ¬í™” ì‹¤ìŠµ\n",
    "############################################################################\n",
    "\n",
    "print(\"ğŸ”„ Pickle ì—­ì§ë ¬í™” ì‹¤ìŠµ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. ë‹¨ì¼ ê°ì²´ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "print(\"1. ë‹¨ì¼ ê°ì²´ ë¶ˆëŸ¬ì˜¤ê¸°\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open(prompt_file, 'rb') as f:\n",
    "    loaded_prompt = pickle.load(f)\n",
    "\n",
    "print(f\"âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¡œë“œ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“ ì›ë³¸ íƒ€ì…: {type(prompt)}\")\n",
    "print(f\"ğŸ“ ë¡œë“œ íƒ€ì…: {type(loaded_prompt)}\")\n",
    "print(f\"ğŸ” íƒ€ì… ë™ì¼ì„±: {type(prompt) == type(loaded_prompt)}\")\n",
    "\n",
    "# 2. ë³µí•© ê°ì²´ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "print(\"\\n2. ë³µí•© ê°ì²´ ë¶ˆëŸ¬ì˜¤ê¸°\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "with open(components_file, 'rb') as f:\n",
    "    loaded_components = pickle.load(f)\n",
    "\n",
    "print(f\"âœ… ëª¨ë¸ ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ”§ ë¡œë“œëœ ì»´í¬ë„ŒíŠ¸: {list(loaded_components.keys())}\")\n",
    "print(f\"ğŸ“Š ë©”íƒ€ë°ì´í„°: {loaded_components['metadata']}\")\n",
    "\n",
    "# 3. ë¡œë“œëœ ê°ì²´ë“¤ í…ŒìŠ¤íŠ¸\n",
    "print(\"\\n3. ë¡œë“œëœ ê°ì²´ë“¤ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# ë¡œë“œëœ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸\n",
    "test_question = \"Pythonì—ì„œ Pickleì˜ ì¥ë‹¨ì ì€?\"\n",
    "loaded_messages = loaded_prompt.format_messages(question=test_question)\n",
    "print(f\"ğŸ“¤ ë¡œë“œëœ í”„ë¡¬í”„íŠ¸: {loaded_messages[0].content}\")\n",
    "\n",
    "# ë¡œë“œëœ LLMìœ¼ë¡œ ì‘ë‹µ ìƒì„±\n",
    "if 'llm_config' in loaded_components:\n",
    "    llm_config = loaded_components['llm_config']\n",
    "    print(f\"ğŸ”§ LLM ì„¤ì • ë¡œë“œ: {llm_config}\")\n",
    "    \n",
    "    # ìƒˆë¡œìš´ LLM ê°ì²´ ìƒì„±\n",
    "    recreated_llm = ChatGoogleGenerativeAI(\n",
    "        model=llm_config['model'],\n",
    "        temperature=llm_config['temperature'],\n",
    "        max_output_tokens=llm_config['max_output_tokens']\n",
    "    )\n",
    "    \n",
    "    response = recreated_llm.invoke(loaded_messages)\n",
    "    print(f\"ğŸ’¬ ì¬ìƒì„±ëœ LLM ì‘ë‹µ: {response.content[:100]}...\")\n",
    "else:\n",
    "    print(\"âš ï¸  LLM ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ì¡´ LLM ì‚¬ìš©...\")\n",
    "    response = llm.invoke(loaded_messages)\n",
    "    print(f\"ğŸ’¬ ê¸°ì¡´ LLM ì‘ë‹µ: {response.content[:100]}...\")\n",
    "\n",
    "# ë¡œë“œëœ ì²´ì¸ ì„¤ì •ì—ì„œ ì²´ì¸ ë³µì›\n",
    "if 'chain_config' in loaded_components:\n",
    "    try:\n",
    "        # JSON ì§ë ¬í™”ëœ ì²´ì¸ ì„¤ì •ì„ ë³µì›\n",
    "        chain_config = loaded_components['chain_config']\n",
    "        restored_chain = loads(json.dumps(chain_config))\n",
    "        \n",
    "        chain_response = restored_chain.invoke({\"question\": test_question})\n",
    "        print(f\"ğŸ”— ë³µì›ëœ ì²´ì¸ ì‘ë‹µ: {chain_response[:100]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  ì²´ì¸ ë³µì› ì—ëŸ¬: {e}\")\n",
    "        print(\"   ê¸°ì¡´ ì²´ì¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸...\")\n",
    "        chain_response = chain.invoke({\"question\": test_question})\n",
    "        print(f\"ğŸ”— ê¸°ì¡´ ì²´ì¸ ì‘ë‹µ: {chain_response[:100]}...\")\n",
    "else:\n",
    "    print(\"âš ï¸  ì²´ì¸ ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(\"\\nâœ… Pickle ì—­ì§ë ¬í™” ì‹¤ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8988c38e",
   "metadata": {},
   "source": [
    "## 5. ëª¨ë¸ ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤ì „ ì˜ˆì œ\n",
    "\n",
    "ì‹¤ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° íŒ¨í„´ì„ êµ¬í˜„í•´ë´…ì‹œë‹¤.\n",
    "\n",
    "### ì‹¤ì „ ì‹œë‚˜ë¦¬ì˜¤\n",
    "1. **ì„¤ì • ì €ì¥**: ëª¨ë¸ íŒŒë¼ë¯¸í„°ì™€ í”„ë¡¬í”„íŠ¸ë¥¼ JSONìœ¼ë¡œ ì €ì¥\n",
    "2. **ëª¨ë¸ ë°±ì—…**: ì „ì²´ ëª¨ë¸ì„ Pickleë¡œ ë°±ì—…\n",
    "3. **ë²„ì „ ê´€ë¦¬**: ë‹¤ì–‘í•œ ë²„ì „ì˜ ëª¨ë¸ ê´€ë¦¬\n",
    "4. **ì•ˆì „í•œ ë¡œë”©**: ì—ëŸ¬ ì²˜ë¦¬ì™€ ê²€ì¦ í¬í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c79e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# ëª¨ë¸ ê´€ë¦¬ í´ë˜ìŠ¤ êµ¬í˜„\n",
    "############################################################################\n",
    "\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "class ModelManager:\n",
    "    \"\"\"LangChain ëª¨ë¸ì˜ ì €ì¥ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, base_dir=\"saved_models\"):\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.base_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    def save_model_config(self, model_name, components):\n",
    "        \"\"\"JSON í˜•íƒœë¡œ ëª¨ë¸ ì„¤ì • ì €ì¥\"\"\"\n",
    "        config_data = {\n",
    "            \"metadata\": {\n",
    "                \"name\": model_name,\n",
    "                \"created_at\": datetime.datetime.now().isoformat(),\n",
    "                \"langchain_version\": \"latest\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # ì§ë ¬í™” ê°€ëŠ¥í•œ ì»´í¬ë„ŒíŠ¸ë“¤ë§Œ ì €ì¥\n",
    "        for name, component in components.items():\n",
    "            if is_lc_serializable(component):\n",
    "                try:\n",
    "                    config_data[name] = dumpd(component)\n",
    "                    print(f\"âœ… {name}: JSON ì €ì¥ ì„±ê³µ\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ {name}: JSON ì €ì¥ ì‹¤íŒ¨ - {e}\")\n",
    "            else:\n",
    "                print(f\"âš ï¸  {name}: ì§ë ¬í™” ë¶ˆê°€ëŠ¥ (JSON ì €ì¥ ì œì™¸)\")\n",
    "        \n",
    "        # JSON íŒŒì¼ ì €ì¥\n",
    "        config_file = self.base_dir / f\"{model_name}_config.json\"\n",
    "        with open(config_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(config_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"ğŸ“ ì„¤ì • íŒŒì¼ ì €ì¥: {config_file}\")\n",
    "        return config_file\n",
    "    \n",
    "    def save_model_pickle(self, model_name, components):\n",
    "        \"\"\"Pickle í˜•íƒœë¡œ ì „ì²´ ëª¨ë¸ ì €ì¥\"\"\"\n",
    "        # LLM ê°ì²´ëŠ” pickleë¡œ ì €ì¥í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì•ˆì „í•œ í˜•íƒœë¡œ ë³€í™˜\n",
    "        safe_components = {}\n",
    "        \n",
    "        for name, component in components.items():\n",
    "            if name == \"llm\":\n",
    "                # LLM ê°ì²´ëŠ” ì„¤ì • ì •ë³´ë§Œ ì €ì¥\n",
    "                safe_components[\"llm_config\"] = {\n",
    "                    \"model\": component.model,\n",
    "                    \"temperature\": component.temperature,\n",
    "                    \"max_output_tokens\": component.max_output_tokens\n",
    "                }\n",
    "                print(f\"âš ï¸  {name}: LLM ê°ì²´ë¥¼ ì„¤ì • ì •ë³´ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥\")\n",
    "            elif name == \"chain\":\n",
    "                # ì²´ì¸ì€ JSON ì§ë ¬í™”í•˜ì—¬ ì €ì¥\n",
    "                try:\n",
    "                    safe_components[\"chain_config\"] = dumpd(component)\n",
    "                    print(f\"âœ… {name}: ì²´ì¸ì„ JSON ì„¤ì •ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ {name}: ì²´ì¸ ì§ë ¬í™” ì‹¤íŒ¨ - {e}\")\n",
    "            else:\n",
    "                # ë‹¤ë¥¸ ì»´í¬ë„ŒíŠ¸ë“¤ì€ pickle ê°€ëŠ¥ì„± í™•ì¸ í›„ ì €ì¥\n",
    "                try:\n",
    "                    pickle.dumps(component)  # í…ŒìŠ¤íŠ¸\n",
    "                    safe_components[name] = component\n",
    "                    print(f\"âœ… {name}: Pickle ì§ë ¬í™” ê°€ëŠ¥\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ {name}: Pickle ì§ë ¬í™” ë¶ˆê°€ - {str(e)[:50]}...\")\n",
    "        \n",
    "        pickle_data = {\n",
    "            \"metadata\": {\n",
    "                \"name\": model_name,\n",
    "                \"created_at\": datetime.datetime.now().isoformat(),\n",
    "                \"python_version\": f\"{os.sys.version_info.major}.{os.sys.version_info.minor}\"\n",
    "            },\n",
    "            \"components\": safe_components\n",
    "        }\n",
    "        \n",
    "        pickle_file = self.base_dir / f\"{model_name}.pkl\"\n",
    "        with open(pickle_file, 'wb') as f:\n",
    "            pickle.dump(pickle_data, f)\n",
    "        \n",
    "        print(f\"ğŸ“ Pickle íŒŒì¼ ì €ì¥: {pickle_file}\")\n",
    "        return pickle_file\n",
    "    \n",
    "    def load_model_config(self, model_name):\n",
    "        \"\"\"JSON ì„¤ì •ì—ì„œ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\"\"\"\n",
    "        config_file = self.base_dir / f\"{model_name}_config.json\"\n",
    "        \n",
    "        if not config_file.exists():\n",
    "            raise FileNotFoundError(f\"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_file}\")\n",
    "        \n",
    "        with open(config_file, 'r', encoding='utf-8') as f:\n",
    "            config_data = json.load(f)\n",
    "        \n",
    "        print(f\"ğŸ“– ì„¤ì • íŒŒì¼ ë¡œë“œ: {config_file}\")\n",
    "        print(f\"ğŸ“Š ë©”íƒ€ë°ì´í„°: {config_data['metadata']}\")\n",
    "        \n",
    "        # ì»´í¬ë„ŒíŠ¸ ë³µì›\n",
    "        components = {}\n",
    "        for name, component_data in config_data.items():\n",
    "            if name != \"metadata\":\n",
    "                try:\n",
    "                    components[name] = loads(json.dumps(component_data))\n",
    "                    print(f\"âœ… {name}: JSON ë³µì› ì„±ê³µ\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ {name}: JSON ë³µì› ì‹¤íŒ¨ - {e}\")\n",
    "        \n",
    "        return components, config_data['metadata']\n",
    "    \n",
    "    def load_model_pickle(self, model_name):\n",
    "        \"\"\"Pickle íŒŒì¼ì—ì„œ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\"\"\"\n",
    "        pickle_file = self.base_dir / f\"{model_name}.pkl\"\n",
    "        \n",
    "        if not pickle_file.exists():\n",
    "            raise FileNotFoundError(f\"Pickle íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pickle_file}\")\n",
    "        \n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            pickle_data = pickle.load(f)\n",
    "        \n",
    "        print(f\"ğŸ“– Pickle íŒŒì¼ ë¡œë“œ: {pickle_file}\")\n",
    "        print(f\"ğŸ“Š ë©”íƒ€ë°ì´í„°: {pickle_data['metadata']}\")\n",
    "        \n",
    "        components = pickle_data['components']\n",
    "        \n",
    "        # LLM ì„¤ì •ì´ ìˆë‹¤ë©´ ìƒˆë¡œìš´ LLM ê°ì²´ ìƒì„±\n",
    "        if 'llm_config' in components:\n",
    "            try:\n",
    "                llm_config = components['llm_config']\n",
    "                components['llm'] = ChatGoogleGenerativeAI(\n",
    "                    model=llm_config['model'],\n",
    "                    temperature=llm_config['temperature'],\n",
    "                    max_output_tokens=llm_config['max_output_tokens']\n",
    "                )\n",
    "                print(\"âœ… LLM ê°ì²´ ì¬ìƒì„± ì™„ë£Œ\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ LLM ê°ì²´ ì¬ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # ì²´ì¸ ì„¤ì •ì´ ìˆë‹¤ë©´ ì²´ì¸ ë³µì›\n",
    "        if 'chain_config' in components:\n",
    "            try:\n",
    "                chain_config = components['chain_config']\n",
    "                components['chain'] = loads(json.dumps(chain_config))\n",
    "                print(\"âœ… ì²´ì¸ ê°ì²´ ë³µì› ì™„ë£Œ\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ì²´ì¸ ê°ì²´ ë³µì› ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        return components, pickle_data['metadata']\n",
    "    \n",
    "    def list_saved_models(self):\n",
    "        \"\"\"ì €ì¥ëœ ëª¨ë¸ ëª©ë¡ ë°˜í™˜\"\"\"\n",
    "        models = []\n",
    "        for file in self.base_dir.glob(\"*\"):\n",
    "            if file.suffix == \".json\" and \"_config\" in file.name:\n",
    "                model_name = file.name.replace(\"_config.json\", \"\")\n",
    "                models.append({\n",
    "                    \"name\": model_name,\n",
    "                    \"config_file\": file,\n",
    "                    \"pickle_file\": self.base_dir / f\"{model_name}.pkl\"\n",
    "                })\n",
    "        return models\n",
    "\n",
    "# ModelManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "model_manager = ModelManager()\n",
    "print(\"ğŸ¯ ModelManager ì´ˆê¸°í™” ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d09aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# ì‹¤ì „ ì˜ˆì œ ì‹¤í–‰\n",
    "############################################################################\n",
    "\n",
    "print(\"ğŸš€ ì‹¤ì „ ëª¨ë¸ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° ì˜ˆì œ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. ëª¨ë¸ ì €ì¥\n",
    "print(\"1. ëª¨ë¸ ì €ì¥í•˜ê¸°\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# ì €ì¥í•  ì»´í¬ë„ŒíŠ¸ë“¤ ì¤€ë¹„\n",
    "my_components = {\n",
    "    \"llm\": llm,\n",
    "    \"prompt\": prompt,\n",
    "    \"parser\": parser,\n",
    "    \"chain\": chain\n",
    "}\n",
    "\n",
    "model_name = \"gemini_qa_model_v1\"\n",
    "\n",
    "# JSON ì„¤ì • ì €ì¥\n",
    "print(\"ğŸ”§ JSON ì„¤ì • ì €ì¥ ì¤‘...\")\n",
    "config_file = model_manager.save_model_config(model_name, my_components)\n",
    "\n",
    "# Pickle ì „ì²´ ì €ì¥\n",
    "print(\"\\nğŸ¥’ Pickle ì „ì²´ ì €ì¥ ì¤‘...\")\n",
    "pickle_file = model_manager.save_model_pickle(model_name, my_components)\n",
    "\n",
    "# 2. ì €ì¥ëœ ëª¨ë¸ ëª©ë¡ í™•ì¸\n",
    "print(\"\\n\\n2. ì €ì¥ëœ ëª¨ë¸ ëª©ë¡\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "saved_models = model_manager.list_saved_models()\n",
    "for model_info in saved_models:\n",
    "    config_exists = model_info[\"config_file\"].exists()\n",
    "    pickle_exists = model_info[\"pickle_file\"].exists()\n",
    "    \n",
    "    print(f\"ğŸ“‹ ëª¨ë¸ëª…: {model_info['name']}\")\n",
    "    print(f\"   âœ… ì„¤ì • íŒŒì¼: {'ìˆìŒ' if config_exists else 'ì—†ìŒ'}\")\n",
    "    print(f\"   âœ… Pickle íŒŒì¼: {'ìˆìŒ' if pickle_exists else 'ì—†ìŒ'}\")\n",
    "\n",
    "print(\"\\nâœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d7e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë° í…ŒìŠ¤íŠ¸\n",
    "############################################################################\n",
    "\n",
    "print(\"ğŸ“‚ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë° í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. JSON ì„¤ì •ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "print(\"1. JSON ì„¤ì •ì—ì„œ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "try:\n",
    "    json_components, json_metadata = model_manager.load_model_config(model_name)\n",
    "    print(f\"âœ… JSON ë¶ˆëŸ¬ì˜¤ê¸° ì„±ê³µ!\")\n",
    "    print(f\"ğŸ“Š ë¶ˆëŸ¬ì˜¨ ì»´í¬ë„ŒíŠ¸: {list(json_components.keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ JSON ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}\")\n",
    "    json_components = None\n",
    "\n",
    "# 2. Pickleì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "print(\"\\n2. Pickleì—ì„œ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "try:\n",
    "    pickle_components, pickle_metadata = model_manager.load_model_pickle(model_name)\n",
    "    print(f\"âœ… Pickle ë¶ˆëŸ¬ì˜¤ê¸° ì„±ê³µ!\")\n",
    "    print(f\"ğŸ“Š ë¶ˆëŸ¬ì˜¨ ì»´í¬ë„ŒíŠ¸: {list(pickle_components.keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Pickle ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}\")\n",
    "    pickle_components = None\n",
    "\n",
    "# 3. ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ë“¤ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\n",
    "print(\"\\n3. ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ë“¤ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "test_question = \"LangChain ëª¨ë¸ ì§ë ¬í™”ì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "print(f\"ğŸ§ª í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {test_question}\")\n",
    "\n",
    "# JSON ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
    "if json_components and \"prompt\" in json_components:\n",
    "    try:\n",
    "        json_prompt = json_components[\"prompt\"]\n",
    "        json_messages = json_prompt.format_messages(question=test_question)\n",
    "        json_response = llm.invoke(json_messages)\n",
    "        print(f\"\\nğŸ“„ JSON ëª¨ë¸ ì‘ë‹µ: {json_response.content[:100]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ JSON ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# Pickle ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
    "if pickle_components:\n",
    "    try:\n",
    "        pickle_chain = pickle_components[\"chain\"]\n",
    "        pickle_response = pickle_chain.invoke({\"question\": test_question})\n",
    "        print(f\"\\nğŸ¥’ Pickle ëª¨ë¸ ì‘ë‹µ: {pickle_response[:100]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Pickle ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(\"\\nâœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° ë° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e843fc00",
   "metadata": {},
   "source": [
    "## 6. ì²´ì¸ ì§ë ¬í™” ì‹¤ìŠµ\n",
    "\n",
    "ë³µì¡í•œ LangChain ì²´ì¸ì˜ ì§ë ¬í™”ë¥¼ ì—°ìŠµí•´ë´…ì‹œë‹¤.\n",
    "\n",
    "### ì²´ì¸ ì§ë ¬í™”ì˜ ì¤‘ìš”ì„±\n",
    "- **ì¬ì‚¬ìš©ì„±**: ë³µì¡í•œ ì²´ì¸ êµ¬ì„±ì„ ì¬ì‚¬ìš©\n",
    "- **ë°°í¬**: í”„ë¡œë•ì…˜ í™˜ê²½ì— ì²´ì¸ ë°°í¬\n",
    "- **ë²„ì „ ê´€ë¦¬**: ì²´ì¸ì˜ ë‹¤ì–‘í•œ ë²„ì „ ê´€ë¦¬\n",
    "- **í˜‘ì—…**: íŒ€ì› ê°„ ì²´ì¸ ê³µìœ \n",
    "\n",
    "### ì§ë ¬í™” ê°€ëŠ¥í•œ ì²´ì¸ vs ë¶ˆê°€ëŠ¥í•œ ì²´ì¸\n",
    "- âœ… **ê°€ëŠ¥**: LangChain ê¸°ë³¸ ì»´í¬ë„ŒíŠ¸ë¡œë§Œ êµ¬ì„±ëœ ì²´ì¸\n",
    "- âŒ **ë¶ˆê°€ëŠ¥**: ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ë‚˜ ëŒë‹¤ê°€ í¬í•¨ëœ ì²´ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc29b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# ë³µì¡í•œ ì²´ì¸ ìƒì„± ë° ì§ë ¬í™”\n",
    "# ğŸ’¡LangChainì—ì„œ ì§ë ¬í™” ê°€ëŠ¥í•œ ì²´ì¸ì„ ë§Œë“¤ ë•Œì˜ í•µì‹¬ ì›ì¹™:\n",
    "#   - ê°€ëŠ¥í•œ í•œ LangChainì˜ ê¸°ë³¸ ì»´í¬ë„ŒíŠ¸ë§Œ ì‚¬ìš©\n",
    "#   - ì»¤ìŠ¤í…€ í•¨ìˆ˜ë‚˜ ëŒë‹¤ í•¨ìˆ˜ëŠ” ì§ë ¬í™”ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ í”¼í•˜ê¸°\n",
    "#   - í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ê³ ì • ê°’ë“¤ì„ ì§ì ‘ í¬í•¨ì‹œí‚¤ê¸°\n",
    "############################################################################\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "\n",
    "print(\"ğŸ”— ë³µì¡í•œ ì²´ì¸ ì§ë ¬í™” ì‹¤ìŠµ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. ë‹¤ì–‘í•œ íƒ€ì…ì˜ ì²´ì¸ ìƒì„±\n",
    "print(\"1. ë‹¤ì–‘í•œ íƒ€ì…ì˜ ì²´ì¸ ìƒì„±\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# ê¸°ë³¸ ìˆœì°¨ ì²´ì¸\n",
    "basic_chain = prompt | llm | parser\n",
    "print(f\"âœ… ê¸°ë³¸ ì²´ì¸: {is_lc_serializable(basic_chain)}\")\n",
    "\n",
    "# ë³‘ë ¬ ì²´ì¸\n",
    "summary_prompt = ChatPromptTemplate.from_template(\"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”: {text}\")\n",
    "analysis_prompt = ChatPromptTemplate.from_template(\"ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ì£¼ìš” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”: {text}\")\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"summary\": summary_prompt | llm | parser,\n",
    "    \"keywords\": analysis_prompt | llm | parser\n",
    "})\n",
    "print(f\"âœ… ë³‘ë ¬ ì²´ì¸: {is_lc_serializable(parallel_chain)}\")\n",
    "\n",
    "# ì¡°ê±´ë¶€ ì²´ì¸ (ë” ê°„ë‹¨í•œ ì ‘ê·¼ë²•)\n",
    "conditional_prompt = ChatPromptTemplate.from_template(\n",
    "    \"ì§ˆë¬¸: {question}\\n\\në‹µë³€í•´ì£¼ì„¸ìš”:\"\n",
    ")\n",
    "\n",
    "# ë‹¨ìˆœí•œ ì²´ì¸ìœ¼ë¡œ êµ¬ì„± (ì§ë ¬í™” ê°€ëŠ¥)\n",
    "conditional_chain = conditional_prompt | llm | parser\n",
    "print(f\"âœ… ì¡°ê±´ë¶€ ì²´ì¸: {is_lc_serializable(conditional_chain)}\")\n",
    "\n",
    "# ë˜ëŠ” ì§ˆë¬¸ íƒ€ì…ì„ í¬í•¨í•œ ë‹¤ë¥¸ ì ‘ê·¼ë²•\n",
    "enhanced_prompt = ChatPromptTemplate.from_template(\n",
    "    \"ë‹¤ìŒì€ ì¼ë°˜ì ì¸ ì§ˆë¬¸ì…ë‹ˆë‹¤.\\nì§ˆë¬¸: {question}\\n\\në‹µë³€í•´ì£¼ì„¸ìš”:\"\n",
    ")\n",
    "\n",
    "enhanced_chain = enhanced_prompt | llm | parser\n",
    "print(f\"âœ… í–¥ìƒëœ ì²´ì¸: {is_lc_serializable(enhanced_chain)}\")\n",
    "\n",
    "# 2. ì²´ì¸ë“¤ì˜ ì§ë ¬í™” í…ŒìŠ¤íŠ¸\n",
    "print(\"\\n2. ì²´ì¸ë“¤ì˜ ì§ë ¬í™” í…ŒìŠ¤íŠ¸\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "chains_to_test = {\n",
    "    \"basic_chain\": basic_chain,\n",
    "    \"parallel_chain\": parallel_chain,\n",
    "    \"conditional_chain\": conditional_chain,\n",
    "    \"enhanced_chain\": enhanced_chain\n",
    "}\n",
    "\n",
    "serialized_chains = {}\n",
    "\n",
    "for name, chain in chains_to_test.items():\n",
    "    try:\n",
    "        # JSON ì§ë ¬í™” ì‹œë„\n",
    "        chain_json = dumps(chain)\n",
    "        serialized_chains[name] = chain_json\n",
    "        print(f\"âœ… {name}: JSON ì§ë ¬í™” ì„±ê³µ ({len(chain_json)} ë¬¸ì)\")\n",
    "        \n",
    "        # ì—­ì§ë ¬í™” í…ŒìŠ¤íŠ¸\n",
    "        restored_chain = loads(chain_json)\n",
    "        print(f\"   â†³ ì—­ì§ë ¬í™”: âœ… ì„±ê³µ\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {name}: ì§ë ¬í™” ì‹¤íŒ¨ - {e}\")\n",
    "\n",
    "print(\"\\nâœ… ì²´ì¸ ì§ë ¬í™” í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5322c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# ì§ë ¬í™”ëœ ì²´ì¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n",
    "############################################################################\n",
    "\n",
    "print(\"ğŸ§ª ì§ë ¬í™”ëœ ì²´ì¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°\n",
    "test_inputs = {\n",
    "    \"basic_chain\": {\"question\": \"LangChainì´ë€ ë¬´ì—‡ì¸ê°€ìš”?\"},\n",
    "    \"parallel_chain\": {\"text\": \"LangChainì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\"},\n",
    "    \"conditional_chain\": {\"question\": \"Pythonì˜ ì¥ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\"},\n",
    "    \"enhanced_chain\": {\"question\": \"AIì˜ ë¯¸ë˜ëŠ” ì–´ë–¨ê¹Œìš”?\"}\n",
    "}\n",
    "\n",
    "# ê° ì²´ì¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n",
    "for chain_name in serialized_chains.keys():\n",
    "    if chain_name in test_inputs:\n",
    "        print(f\"\\nğŸ”— {chain_name} í…ŒìŠ¤íŠ¸\")\n",
    "        print(\"-\" * 25)\n",
    "        \n",
    "        try:\n",
    "            # ì›ë³¸ ì²´ì¸ ì‹¤í–‰\n",
    "            original_chain = chains_to_test[chain_name]\n",
    "            original_result = original_chain.invoke(test_inputs[chain_name])\n",
    "            \n",
    "            # ì§ë ¬í™”ëœ ì²´ì¸ ë³µì› ë° ì‹¤í–‰\n",
    "            restored_chain = loads(serialized_chains[chain_name])\n",
    "            restored_result = restored_chain.invoke(test_inputs[chain_name])\n",
    "            \n",
    "            print(f\"ğŸ“¤ ì…ë ¥: {test_inputs[chain_name]}\")\n",
    "            \n",
    "            if isinstance(original_result, dict):\n",
    "                print(f\"ğŸ“¥ ì›ë³¸ ê²°ê³¼: {str(original_result)[:100]}...\")\n",
    "                print(f\"ğŸ”„ ë³µì› ê²°ê³¼: {str(restored_result)[:100]}...\")\n",
    "            else:\n",
    "                print(f\"ğŸ“¥ ì›ë³¸ ê²°ê³¼: {original_result[:100]}...\")\n",
    "                print(f\"ğŸ”„ ë³µì› ê²°ê³¼: {restored_result[:100]}...\")\n",
    "                \n",
    "            print(\"âœ… ì‹¤í–‰ ì„±ê³µ!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(\"\\n\\nğŸ¯ ì²´ì¸ ì§ë ¬í™” ì‹¤ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd059ec",
   "metadata": {},
   "source": [
    "## ì •ë¦¬ ë° ëª¨ë²” ì‚¬ë¡€\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œ ë°°ìš´ LangChain ëª¨ë¸ ì§ë ¬í™” ë°©ë²•ë“¤ì„ ì •ë¦¬í•´ë´…ì‹œë‹¤.\n",
    "\n",
    "### ğŸ¯ ì£¼ìš” í•™ìŠµ ë‚´ìš©\n",
    "\n",
    "1. **ì§ë ¬í™” ê°€ëŠ¥ì„± í™•ì¸**: `is_lc_serializable()` í•¨ìˆ˜ í™œìš©\n",
    "2. **JSON ì§ë ¬í™”**: `dumps()`, `dumpd()`, `loads()` í•¨ìˆ˜ ì‚¬ìš©\n",
    "3. **Pickle ì§ë ¬í™”**: Pythonì˜ `pickle` ëª¨ë“ˆ í™œìš©\n",
    "4. **ëª¨ë¸ ê´€ë¦¬**: ì²´ê³„ì ì¸ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸° ì‹œìŠ¤í…œ êµ¬ì¶•\n",
    "5. **ì²´ì¸ ì§ë ¬í™”**: ë³µì¡í•œ ì²´ì¸ì˜ ì €ì¥ê³¼ ë³µì›\n",
    "\n",
    "### ğŸ“‹ ì§ë ¬í™” ë°©ë²• ì„ íƒ ê°€ì´ë“œ\n",
    "\n",
    "| ìƒí™© | ì¶”ì²œ ë°©ë²• | ì´ìœ  |\n",
    "|------|-----------|------|\n",
    "| **ì„¤ì • ê³µìœ ** | JSON (`dumps`) | ê°€ë…ì„±, í”Œë«í¼ ë…ë¦½ì„± |\n",
    "| **í”„ë¡œë•ì…˜ ë°°í¬** | JSON + ê²€ì¦ | ì•ˆì •ì„±, ë²„ì „ ê´€ë¦¬ |\n",
    "| **ê°œë°œ/í…ŒìŠ¤íŠ¸** | Pickle | ì™„ì „ì„±, í¸ì˜ì„± |\n",
    "| **íŒ€ í˜‘ì—…** | JSON | í˜¸í™˜ì„±, ë””ë²„ê¹… ìš©ì´ |\n",
    "| **ëª¨ë¸ ë°±ì—…** | Pickle | ì „ì²´ ìƒíƒœ ë³´ì¡´ |\n",
    "\n",
    "### âš ï¸ ì£¼ì˜ì‚¬í•­\n",
    "\n",
    "1. **ë³´ì•ˆ**: Pickle íŒŒì¼ì€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ì—ì„œë§Œ ë¡œë“œ\n",
    "2. **ë²„ì „ í˜¸í™˜ì„±**: LangChain ë²„ì „ ë³€ê²½ ì‹œ ì§ë ¬í™” í˜¸í™˜ì„± í™•ì¸\n",
    "3. **API í‚¤**: ì§ë ¬í™” ì‹œ ë¯¼ê°í•œ ì •ë³´ ì œì™¸\n",
    "4. **íŒŒì¼ ê´€ë¦¬**: ì •ê¸°ì ì¸ ì •ë¦¬ë¡œ ë””ìŠ¤í¬ ê³µê°„ ê´€ë¦¬\n",
    "5. **í…ŒìŠ¤íŠ¸**: ì§ë ¬í™”/ì—­ì§ë ¬í™” í›„ í•­ìƒ ë™ì‘ ê²€ì¦\n",
    "\n",
    "### ğŸš€ ì‹¤ì „ í™œìš© íŒ\n",
    "\n",
    "1. **ë²„ì „ íƒœê¹…**: ëª¨ë¸ íŒŒì¼ì— ë²„ì „ ì •ë³´ í¬í•¨\n",
    "2. **ë©”íƒ€ë°ì´í„°**: ìƒì„± ì¼ì‹œ, í™˜ê²½ ì •ë³´ ì €ì¥\n",
    "3. **ì—ëŸ¬ ì²˜ë¦¬**: ë¡œë”© ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ë°©ì•ˆ ì¤€ë¹„\n",
    "4. **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ì§ë ¬í™”ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ ì¶”ì \n",
    "5. **ë°±ì—… ì „ëµ**: ì¤‘ìš”í•œ ëª¨ë¸ì˜ ë‹¤ì¤‘ ë°±ì—… ìœ ì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9056a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# ìƒì„±ëœ íŒŒì¼ë“¤ ì •ë¦¬ (ì„ íƒì‚¬í•­)\n",
    "############################################################################\n",
    "\n",
    "print(\"ğŸ§¹ ìƒì„±ëœ íŒŒì¼ë“¤ ì •ë¦¬\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# ì •ë¦¬í•  íŒŒì¼ë“¤ ëª©ë¡\n",
    "files_to_clean = [\n",
    "    \"prompt_template.pkl\",\n",
    "    \"model_components.pkl\"\n",
    "]\n",
    "\n",
    "# ìƒì„±ëœ ëª¨ë¸ ë””ë ‰í† ë¦¬ë„ í¬í•¨\n",
    "if model_manager.base_dir.exists():\n",
    "    for file in model_manager.base_dir.glob(\"*\"):\n",
    "        files_to_clean.append(str(file))\n",
    "\n",
    "print(\"ğŸ“ ì •ë¦¬ ëŒ€ìƒ íŒŒì¼ë“¤:\")\n",
    "for file_path in files_to_clean:\n",
    "    if os.path.exists(file_path):\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        print(f\"   {file_path} ({file_size} bytes)\")\n",
    "    else:\n",
    "        print(f\"   {file_path} (ì¡´ì¬í•˜ì§€ ì•ŠìŒ)\")\n",
    "\n",
    "# íŒŒì¼ ì‚­ì œ ì—¬ë¶€ ì„ íƒ\n",
    "print(f\"\\nì´ {len([f for f in files_to_clean if os.path.exists(f)])} ê°œì˜ íŒŒì¼ì´ ì •ë¦¬ ëŒ€ìƒì…ë‹ˆë‹¤.\")\n",
    "print(\"íŒŒì¼ë“¤ì„ ì‚­ì œí•˜ë ¤ë©´ ì•„ë˜ ì¤„ì˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”:\")\n",
    "print(\"# cleanup_files = True\")\n",
    "\n",
    "cleanup_files = False  # Trueë¡œ ë³€ê²½í•˜ë©´ íŒŒì¼ ì‚­ì œ\n",
    "\n",
    "if cleanup_files:\n",
    "    deleted_count = 0\n",
    "    for file_path in files_to_clean:\n",
    "        try:\n",
    "            if os.path.exists(file_path):\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.remove(file_path)\n",
    "                    print(f\"ğŸ—‘ï¸  ì‚­ì œë¨: {file_path}\")\n",
    "                    deleted_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì‚­ì œ ì‹¤íŒ¨: {file_path} - {e}\")\n",
    "    \n",
    "    # ë¹ˆ ë””ë ‰í† ë¦¬ ì‚­ì œ\n",
    "    try:\n",
    "        if model_manager.base_dir.exists() and not any(model_manager.base_dir.iterdir()):\n",
    "            model_manager.base_dir.rmdir()\n",
    "            print(f\"ğŸ—‘ï¸  ë¹ˆ ë””ë ‰í† ë¦¬ ì‚­ì œ: {model_manager.base_dir}\")\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    print(f\"\\nâœ… ì´ {deleted_count}ê°œ íŒŒì¼ì´ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"\\nğŸ’¡ ì •ë¦¬ë¥¼ ì›í•˜ë©´ ìœ„ì˜ cleanup_files ë³€ìˆ˜ë¥¼ Trueë¡œ ì„¤ì •í•˜ì„¸ìš”.\")\n",
    "\n",
    "print(\"\\nğŸ‰ LangChain ëª¨ë¸ ì§ë ¬í™” ì‹¤ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(\"ğŸ“š ë°°ìš´ ë‚´ìš©ì„ ì‹¤ì œ í”„ë¡œì íŠ¸ì— ì ìš©í•´ë³´ì„¸ìš”!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
